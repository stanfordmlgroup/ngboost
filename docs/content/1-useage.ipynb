{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "We'll start with a probabilistic regression example on the Boston housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/c242587/Desktop/projects/git/ngboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=3.6231 val_loss=0.0000 scale=0.5000 norm=3.3059\n",
      "[iter 100] loss=3.0349 val_loss=0.0000 scale=2.0000 norm=7.1655\n",
      "[iter 200] loss=2.3596 val_loss=0.0000 scale=2.0000 norm=3.7977\n",
      "[iter 300] loss=1.9685 val_loss=0.0000 scale=2.0000 norm=3.0467\n",
      "[iter 400] loss=1.7957 val_loss=0.0000 scale=1.0000 norm=1.3911\n",
      "Test MSE 11.751316258028782\n",
      "Test NLL 3.7006980539890253\n"
     ]
    }
   ],
   "source": [
    "from ngboost import NGBRegressor\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, Y = load_boston(True)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "ngb = NGBRegressor().fit(X_train, Y_train)\n",
    "Y_preds = ngb.predict(X_test)\n",
    "Y_dists = ngb.pred_dist(X_test)\n",
    "\n",
    "# test Mean Squared Error\n",
    "test_MSE = mean_squared_error(Y_preds, Y_test)\n",
    "print('Test MSE', test_MSE)\n",
    "\n",
    "# test Negative Log Likelihood\n",
    "test_NLL = -Y_dists.logpdf(Y_test).mean()\n",
    "print('Test NLL', test_NLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the estimated distributional parameters at a set of points is easy. This returns the predicted mean and standard deviation of the first five observations in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc': array([23.46378107, 16.37767307, 23.47872484, 33.74513435, 24.77121111]),\n",
       " 'scale': array([1.28837356, 1.25869559, 1.03021179, 1.01968677, 1.01327948])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dists[0:5].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "NGBoost can be used with a variety of distributions, broken down into those for regression (support on an infinite set) and those for classification (support on a finite set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Distribution | Parameters | Implemented Scores | Reference |\n",
    "| --- | --- | --- | --- |\n",
    "| `Normal` | `loc`, `scale` | `LogScore`, `CRPScore` | [`scipy.stats` normal](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) |\n",
    "| `LogNormal` | `s`, `scale` | `LogScore`, `CRPScore` | [`scipy.stats` lognormal](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html) |\n",
    "| `Exponential` | `scale` | `LogScore`, `CRPScore` | [`scipy.stats` exponential](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression distributions can be used through the `NGBRegressor()` constructor by passing the appropriate class as the `Dist` argument. `Normal` is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngboost.distns import Exponential, Normal\n",
    "\n",
    "X, Y = load_boston(True)\n",
    "X_reg_train, X_reg_test, Y_reg_train, Y_reg_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "ngb_norm = NGBRegressor(Dist=Normal, verbose=False).fit(X_reg_train, Y_reg_train)\n",
    "ngb_exp = NGBRegressor(Dist=Exponential, verbose=False).fit(X_reg_train, Y_reg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two prediction methods for `NGBRegressor` objects: `predict()`, which returns point predictions as one would expect from a standard regressor, and `pred_dist()`, which returns a distribution object representing the conditional distribution of $Y|X=x_i$ at the points $x_i$ in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32.03465906, 19.15818411, 19.30217489, 20.94209258, 18.99318666])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngb_norm.predict(X_reg_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.28380823, 20.10027072, 17.55630199, 21.18983355, 18.11223638])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngb_exp.predict(X_reg_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scale': array([22.28380823, 20.10027072, 17.55630199, 21.18983355, 18.11223638])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngb_exp.pred_dist(X_reg_test)[0:5].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survival Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGBoost supports analyses of right-censored data. Any distribution that can be used for regression in NGBoost can also be used for survival analysis in theory, but this requires the implementation of the right-censored version of the appropriate score. At the moment, `LogNormal` and `Exponential` have these scores implemented. To do survival analysis, use `NGBSurvival` and pass both the time-to-event (or censoring) and event indicator vectors to  `fit()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=1.2578 val_loss=0.0000 scale=4.0000 norm=2.3885\n",
      "[iter 100] loss=0.5902 val_loss=0.0000 scale=2.0000 norm=0.7520\n",
      "[iter 200] loss=0.3591 val_loss=0.0000 scale=4.0000 norm=0.9354\n",
      "[iter 300] loss=0.2541 val_loss=0.0000 scale=2.0000 norm=0.3104\n",
      "[iter 400] loss=0.1479 val_loss=0.0000 scale=4.0000 norm=0.3567\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ngboost import NGBSurvival\n",
    "from ngboost.distns import LogNormal\n",
    "\n",
    "X, Y = load_boston(True)\n",
    "X_surv_train, X_surv_test, Y_surv_train, Y_surv_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# introduce administrative censoring to simulate survival data\n",
    "T_surv_train = np.minimum(Y_train, 30) # time of an event or censoring\n",
    "E_surv_train = Y_train > 30 # 1 if T[i] is the time of an event, 0 if it's a time of censoring\n",
    "\n",
    "ngb = NGBSurvival(Dist=LogNormal).fit(X_surv_train, T_surv_train, E_surv_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores currently implemented assume that the censoring is independent of survival, conditional on the observed predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Distribution | Parameters | Implemented Scores | Reference |\n",
    "| --- | --- | --- | --- |\n",
    "| `k_categorical(K)` | `p0`, `p1`... `p{K-1}` | `LogScore` | [Categorical distribution on Wikipedia](https://en.wikipedia.org/wiki/Categorical_distribution) |\n",
    "| `Bernoulli` | `p` | `LogScore` | [Bernoulli distribution on Wikipedia](https://en.wikipedia.org/wiki/Bernoulli_distribution) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification distributions can be used through the `NGBClassifier()` constructor by passing the appropriate class as the `Dist` argument. `Bernoulli` is the default and is equivalent to `k_categorical(2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngboost import NGBClassifier\n",
    "from ngboost.distns import k_categorical, Bernoulli\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X, y = load_breast_cancer(True)\n",
    "y[0:15] = 2 # artificially make this a 3-class problem instead of a 2-class problem\n",
    "X_cls_train, X_cls_test, Y_cls_train, Y_cls_test  = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "ngb_cat = NGBClassifier(Dist=k_categorical(3), verbose=False) # tell ngboost that there are 3 possible outcomes\n",
    "_ = ngb_cat.fit(X_cls_train, Y_cls_train) # Y should have only 3 values: {0,1,2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using NGBoost for classification, the outcome vector `Y` must consist only of integers from 0 to K-1, where K is the total number of classes. This is consistent with the classification standards in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NGBClassifier` objects have three prediction methods: `predict()` returns the most likely class, `predict_proba()` returns the class probabilities, and `pred_dist()` returns the distribution object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngb_cat.predict(X_cls_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.28228735e-04, 9.99260196e-01, 1.15752705e-05],\n",
       "       [7.28206439e-04, 9.99229602e-01, 4.21917010e-05],\n",
       "       [7.28207212e-04, 9.99230662e-01, 4.11305541e-05],\n",
       "       [7.28206439e-04, 9.99229602e-01, 4.21917010e-05],\n",
       "       [7.28206439e-04, 9.99229602e-01, 4.21917010e-05]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngb_cat.predict_proba(X_cls_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p0': array([0.00072823, 0.00072821, 0.00072821, 0.00072821, 0.00072821]),\n",
       " 'p1': array([0.9992602 , 0.9992296 , 0.99923066, 0.9992296 , 0.9992296 ]),\n",
       " 'p2': array([1.15752705e-05, 4.21917010e-05, 4.11305541e-05, 4.21917010e-05,\n",
       "        4.21917010e-05])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngb_cat.pred_dist(X_cls_test)[0:5].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGBoost supports the log score (`LogScore`, also known as negative log-likelihood) and CRPS (`CRPScore`), although each score may not be implemented for each distribution. The score is specified by the `Score` argument in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGBClassifier(Base=DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                                         max_features=None, max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1,\n",
       "                                         min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         presort=False, random_state=None,\n",
       "                                         splitter='best'),\n",
       "              Dist=<class 'ngboost.distns.categorical.k_categorical.<locals>.Categorical'>,\n",
       "              Score=<class 'ngboost.scores.LogScore'>, col_sample=1.0,\n",
       "              learning_rate=0.01, minibatch_frac=1.0, n_estimators=500,\n",
       "              natural_gradient=True,\n",
       "              random_state=RandomState(MT19937) at 0x119C48D10, tol=0.0001,\n",
       "              verbose=False, verbose_eval=100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ngboost.scores import LogScore, CRPScore\n",
    "\n",
    "NGBRegressor(Dist=Exponential, Score=CRPScore, verbose=False).fit(X_reg_train, Y_reg_train)\n",
    "NGBClassifier(Dist=k_categorical(3), Score=LogScore, verbose=False).fit(X_cls_train, Y_cls_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGBoost can be used with any sklearn regressor as the base learner, specified with the `Base` argument. The default is a depth-3 regression tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGBSurvival(Base=DecisionTreeRegressor(criterion='friedman_mse', max_depth=5,\n",
       "                                       max_features=None, max_leaf_nodes=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       presort=False, random_state=None,\n",
       "                                       splitter='best'),\n",
       "            Dist=<class 'ngboost.api.NGBSurvival.__init__.<locals>.SurvivalDistn'>,\n",
       "            Score=<class 'ngboost.scores.CRPScore'>, col_sample=1.0,\n",
       "            learning_rate=0.01, minibatch_frac=1.0, n_estimators=500,\n",
       "            natural_gradient=True,\n",
       "            random_state=RandomState(MT19937) at 0x119C48D10, tol=0.0001,\n",
       "            verbose=False, verbose_eval=100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "learner = DecisionTreeRegressor(criterion='friedman_mse', max_depth=5)\n",
    "\n",
    "NGBSurvival(Dist=Exponential, Score=CRPScore, Base=learner, verbose=False).fit(X_surv_train, T_surv_train, E_surv_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate, number of estimators, minibatch fraction, and column subsampling are also easily adjusted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=3.5985 val_loss=0.0000 scale=0.5000 norm=3.2693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NGBRegressor(Base=DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort=False, random_state=None,\n",
       "                                        splitter='best'),\n",
       "             Dist=<class 'ngboost.distns.normal.Normal'>,\n",
       "             Score=<class 'ngboost.scores.LogScore'>, col_sample=0.5,\n",
       "             learning_rate=0.01, minibatch_frac=0.5, n_estimators=100,\n",
       "             natural_gradient=True,\n",
       "             random_state=RandomState(MT19937) at 0x119C48D10, tol=0.0001,\n",
       "             verbose=True, verbose_eval=100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngb = NGBRegressor(n_estimators=100, learning_rate=0.01, \n",
    "             minibatch_frac=0.5, col_sample=0.5)\n",
    "ngb.fit(X_reg_train, Y_reg_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
