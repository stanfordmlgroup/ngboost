{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/c242587/Desktop/projects/git/ngboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "from ngboost import NGBClassifier, NGBRegressor\n",
    "from ngboost.distns import k_categorical, Normal\n",
    "from ngboost.scores import LogScore\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = load_boston(True)\n",
    "X_reg_train, X_reg_test, Y_reg_train, Y_reg_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "X, y = load_breast_cancer(True)\n",
    "y[0:15] = 2 # artificially make this a 3-class problem instead of a 2-class problem\n",
    "X_cls_train, X_cls_test, Y_cls_train, Y_cls_test  = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staged Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fit NGBoost objects support staged prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_cls = NGBClassifier(Dist=k_categorical(3), Score=LogScore, n_estimators=500, verbose=False).fit(X_cls_train, Y_cls_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, to get the predictions on the first 5 examples after fitting 415 base learners, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ngb_cls.staged_predict(X_cls_test)\n",
    "preds[415][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p0': array([0.99074995, 0.91368635, 0.00517919, 0.00517919, 0.00517919]),\n",
       " 'p1': array([0.00860966, 0.03267806, 0.99450359, 0.99450359, 0.99450359]),\n",
       " 'p2': array([0.00064039, 0.05363559, 0.00031722, 0.00031722, 0.00031722])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dists = ngb_cls.staged_pred_dist(X_cls_test)\n",
    "pred_dists[415][0:5].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful in conjunction with tracking errors on a validation set, which you can do by passing the `X_val` and `Y_val` arguments and then inspecting the `.best_val_loss_itr` instance attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=3.6556 val_loss=3.5575 scale=0.5000 norm=3.4142\n",
      "[iter 100] loss=3.1118 val_loss=3.1284 scale=1.0000 norm=3.9174\n",
      "[iter 200] loss=2.4839 val_loss=2.6398 scale=2.0000 norm=4.0907\n",
      "[iter 300] loss=2.0183 val_loss=2.7162 scale=1.0000 norm=1.5637\n",
      "[iter 400] loss=1.8111 val_loss=3.1315 scale=1.0000 norm=1.3983\n",
      "244\n"
     ]
    }
   ],
   "source": [
    "ngb = NGBRegressor()\n",
    "ngb.fit(X_reg_train, Y_reg_train, X_val=X_reg_test, Y_val=Y_reg_test) # use a validation set instead of test set here in your own work\n",
    "print(ngb.best_val_loss_itr)\n",
    "best_preds = ngb.predict(X_reg_test, max_iter=ngb.best_val_loss_itr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGBoost also has early stopping. If an integer `early_stopping_rounds` and a validation set (`X_val`,`Y_val`) are passed to `fit()`, the algorithm will stop running after the validation loss has increased for `early_stopping_rounds` of consecutive iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=3.6556 val_loss=3.5575 scale=0.5000 norm=3.4142\n",
      "[iter 100] loss=3.1118 val_loss=3.1292 scale=1.0000 norm=3.9174\n",
      "[iter 200] loss=2.4839 val_loss=2.6422 scale=2.0000 norm=4.0907\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL234 (val_loss=2.5693)\n"
     ]
    }
   ],
   "source": [
    "_ = NGBRegressor().fit(X_reg_train, Y_reg_train, X_val=X_reg_test, Y_val=Y_reg_test, early_stopping_rounds=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set sample weights can be passed using the `val_sample_weight` argument to `fit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `sklearn` Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` methods are compatible with NGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Base': DecisionTreeRegressor(criterion='friedman_mse', max_depth=4, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best'), 'minibatch_frac': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "b1 = DecisionTreeRegressor(criterion='friedman_mse', max_depth=2)\n",
    "b2 = DecisionTreeRegressor(criterion='friedman_mse', max_depth=4)\n",
    "\n",
    "param_grid = {\n",
    "    'minibatch_frac': [1.0, 0.5],\n",
    "    'Base': [b1, b2]\n",
    "}\n",
    "\n",
    "ngb = NGBRegressor(Dist=Normal, verbose=False)\n",
    "\n",
    "grid_search = GridSearchCV(ngb, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_reg_train, Y_reg_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
